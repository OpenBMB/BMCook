<div align="center">

<h1>ğŸ³ BMCook</h1>

**å¤§æ¨¡å‹å‹ç¼©å·¥å…·åŒ…**

</div>

<p align="center">
  <a href="#overview">æ€»è§ˆ</a> â€¢ <a href="#documentation">æ–‡æ¡£</a> â€¢ <a href="#install">å®‰è£…</a> â€¢ <a href="#quick-start">å¿«é€Ÿä¸Šæ‰‹</a> â€¢ <a href="./README.md" target="_blank">English</a>
<br>
</p>

<p align="center">
	<a href='https://bmcook.readthedocs.io/en/main/'>
	    <img src='https://readthedocs.org/projects/bmcook/badge/?version=main' alt='doc' />
	</a>
	<a href="https://github.com/OpenBMB/BMCook/blob/main/LICENSE">
	    <img alt="github" src="https://img.shields.io/github/license/OpenBMB/BMCook">
	</a>
	<a>
		 <img alt="version" src="https://img.shields.io/badge/version-0.1.0-blue">
	</a>
</p>   

## æœ€æ–°åŠ¨æ€

- 2022/3/20 BMCookæ­£å¼å‘å¸ƒäº†ï¼

<div id="overview"></div>

## æ€»è§ˆ

BMCookæ˜¯ä¸€ä¸ªç”¨äºå¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPLMï¼‰çš„æ¨¡å‹å‹ç¼©å·¥å…·åŒ…ï¼Œå®ƒé›†æˆäº†å¤šç§æ¨¡å‹å‹ç¼©æ–¹æ³•ã€‚ä½ å¯ä»¥ä»¥ä»»ä½•æ–¹å¼ç»„åˆå®ƒä»¬ï¼Œä»¥æ»¡è¶³ç‰¹å®šçš„è®¡ç®—éœ€æ±‚ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬å·¥å…·åŒ…å®ç°äº†ä»¥ä¸‹å››ç§æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼šçŸ¥è¯†è’¸é¦ã€æ¨¡å‹å‰ªæã€æ¨¡å‹é‡åŒ–å’Œæ¨¡å‹ä¸“å®¶åŒ–ã€‚

- **æ”¯æŒå¤šç§æ–¹æ³•** ä¸ç°æœ‰çš„å‹ç¼©å·¥å…·åŒ…ç›¸æ¯”ï¼ŒBMCookæ”¯æŒæ‰€æœ‰ä¸»æµçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åŠ é€Ÿæ–¹æ³•ã€‚
- **ç”¨æˆ·å‹å¥½** åŸºäºBMCookï¼Œç”¨æˆ·åªéœ€å‡ è¡Œä»£ç å°±å¯ä»¥å®ç°ä¸åŒçš„å‹ç¼©æ–¹æ³•ã€‚
- **ä»»æ„ç»„åˆ** å—ç›Šäºè§£è€¦åˆçš„å®ç°æ–¹å¼ï¼Œä¸åŒæ–¹æ³•å¯ä»¥ä»»æ„ç»„åˆä»¥è¿½æ±‚æè‡´å‹ç¼©ã€‚

<div id="documentation"></div>

## æ–‡æ¡£
æˆ‘ä»¬çš„[æ–‡æ¡£](https://bmcook.readthedocs.io/en/main/)æä¾›äº†å…³äºè¯¥å·¥å…·åŒ…çš„æ›´å¤šä¿¡æ¯ã€‚

<div id="install"></div>

## å®‰è£…

BMCookåŸºäºBMTrainè¿›è¡Œå¼€å‘ï¼Œä½¿ç”¨å‰éœ€å…ˆå®‰è£…BMTrain

**ä»PyPIå®‰è£…ï¼ˆæ¨èï¼‰**

```shell
$ pip install bmtrain
```

**ä»æºä»£ç å®‰è£…**

```shell
$ git clone https://github.com/OpenBMB/BMTrain.git
$ cd BMTrain
$ python3 setup.py install
```

æ›´å¤šç»†èŠ‚è¯·è¯·å‚è€ƒ[BMTrain](https://bmtrain.readthedocs.io/en/latest/)çš„å®‰è£…æŒ‡å—ã€‚

å®‰è£…å®ŒBMTrainåï¼Œå†æ‹‰å–æœ¬ä»“åº“ã€‚

```shell
$ git clone git@github.com:OpenBMB/BMCook.git
```

<div id="quick-start"></div>

## å¿«é€Ÿä¸Šæ‰‹

`example`æ–‡ä»¶å¤¹æä¾›äº†åŸºäºGPT-Jï¼ˆ6Bå‚æ•°ï¼‰çš„æ ·ä¾‹ä»£ç ã€‚

æ¨¡å‹é‡åŒ–ï¼š

```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-int8 \
     --model gpt-j-full-int8 \
     --start-lr 1e-4 \
     --load gpt-j.bin
```

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥æ¨¡å‹è’¸é¦ï¼š
```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-int8-distill \
     --model gpt-j-full-int8 \
     --start-lr 1e-4 \
     --load gpt-j.bin \
     --use-kd \
     --kd-mse-last-hidden \
     --kd-loss-scale 1 \
     --load-teacher gpt-j.bin
```

æ¨¡å‹å‰ªæï¼š
```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-prune \
     --model gpt-j-full \
     --start-lr 1e-4 \
     --load gpt-j.bin \
     --use-pruning \
     --use-kd \
     --kd-mse-last-hidden \
     --kd-loss-scale 1 \
     --load-teacher gpt-j.bin
```

ä¸ºäº†æ¨¡å‹ä¸“å®¶åŒ–ï¼Œéœ€è¦æŠŠæ¨¡å‹æ¿€æ´»å‡½æ•°è¿›è¡Œä¸€ä¸ªè½¬æ¢é€‚é…ï¼š
```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-relu \
     --model gpt-j-full-relu \
     --start-lr 1e-4 \
     --load gpt-j.bin \
     --use-kd \
     --kd-mse-last-hidden \
     --kd-loss-scale 1 \
     --load-teacher gpt-j.bin
```

æ¨¡å‹ä¸“å®¶åŒ–ï¼ˆä¸éœ€è¦è®­ç»ƒï¼Œåªéœ€ä¿å­˜ä¸­é—´è®¡ç®—ç»“æœï¼‰ï¼š
```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-moe \
     --model gpt-j-full-relu \
     --start-lr 1e-4 \
     --load gpt-j-relu.bin \
     --save-hidden
```

ä¸æ­¤åŒæ—¶ï¼Œä¸åŒçš„å‹ç¼©æ–¹æ³•å¯ä»¥ä»»æ„ç»„åˆï¼Œä»¥ä¸‹æ˜¯é‡åŒ–ã€å‰ªæå’Œè’¸é¦ç»“åˆçš„æ ·ä¾‹ä»£ç ï¼š
```
    torchrun --nnodes=1 --nproc_per_node=8 --rdzv_id=1 --rdzv_backend=c10d --rdzv_endpoint=localhost train.py \
     --save-dir results/gpt-j-int8-prune-distill \
     --model gpt-j-full-int8 \
     --start-lr 1e-4 \
     --load gpt-j.bin \
     --use-pruning \
     --use-kd \
     --kd-mse-last-hidden \
     --kd-loss-scale 1 \
     --load-teacher gpt-j.bin
```

## å¼€æºç¤¾åŒº

æ¬¢è¿è´¡çŒ®è€…å‚ç…§æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](https://github.com/OpenBMB/BMCook/blob/main/CONTRIBUTING.md)è´¡çŒ®ç›¸å…³ä»£ç ã€‚

æ‚¨ä¹Ÿå¯ä»¥åœ¨å…¶ä»–å¹³å°ä¸æˆ‘ä»¬æ²Ÿé€šäº¤æµ:
- QQç¾¤: 735930538
- å®˜æ–¹ç½‘ç«™: http://www.openbmb.org
- å¾®åš: http://weibo.cn/OpenBMB
- Twitter: https://twitter.com/OpenBMB

## å¼€æºè®¸å¯

è¯¥å·¥å…·åŒ…ä½¿ç”¨[Apache 2.0](https://github.com/OpenBMB/BMCook/blob/main/LICENSE)å¼€æºè®¸å¯è¯ã€‚

## åŠŸèƒ½å¯¹æ¯”

|                 | Model Quantization | Model Pruning | Knowledge Distillation | Model MoEfication |
|-----------------|--------------------|---------------|------------------------|-------------------|
| [TextPruner](https://github.com/airaria/TextPruner)      |       -             | âœ…             |          -              |      -             |
| [TensorFlow Lite](https://www.tensorflow.org/lite) | âœ…                  | âœ…             |          -              |           -        |
| [PyTorch](https://pytorch.org/)         | âœ…                  | âœ…             |            -            |          -         |
| [TextBrewer](https://github.com/airaria/TextBrewer)      |           -         | âœ…             | âœ…                      |         -          |
| BMCook          | âœ…                  | âœ…             | âœ…                      | âœ…                 |

